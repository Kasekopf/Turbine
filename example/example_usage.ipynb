{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "First, we specify the credentials and configuration to use with GCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import turbine\n",
    "import google.oauth2\n",
    "\n",
    "config = turbine.GCEConfig(\n",
    "    project_id='turbine-demo',\n",
    "    zone='us-central1-a',\n",
    "    credentials=google.oauth2.service_account.Credentials.from_service_account_file('../../auth/turbine-demo-34dbd729c354.json'),\n",
    "    service_account = \"turbine-demo-worker@turbine-demo.iam.gserviceaccount.com\",   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `project_id` is the (already existing) GCE project in which to provision all resources.\n",
    "* `zone` is the GCE zone in which to provision all resources.\n",
    "* `credentials` are the credentials to use in the controller to provision resources. It is sufficient for these credentials to have \"Compute Admin\", \"Pub/Sub Admin\", and (to initialize GCS for this example) \"Storage Object Admin\" and \"Storage Admin\" roles assigned.\n",
    "* `service_account` is the email of the service account to use for all VMs. It is sufficient for these credentials to have \"Compute Admin\", \"Logs Writer\", \"Pub/Sub Subscriber\", \"Storage Object Creator\", \"Storage Object Viewer\" roles assigned.\n",
    "\n",
    "If one is especially motivated, one could create a custom role for each of the controller and the shim for fine-grained permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Initializing an engine\n",
    "The central construct in Turbine is a `GCEEngine`, which provides an API both to create tasks and to create VMs on the cloud to execute tasks. Let's create a `GCEEngine` now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_engine = turbine.GCEEngine('example-engine', 'gcr.io/turbine-demo/github.com/kasekopf/turbine:7907e19', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide the engine with a unique identifier (`example-engine`), a docker image to run on all VMs (`gcr.io/turbine-demo/github.com/kasekopf/turbine:d091bed`, produced from [this Dockerfile](Dockerfile)), and the GCE configuration information (`config`). Note that the provided docker image must have `turbine` installed, and any `ENTRYPOINT` set on the docker image will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the engine, we prepare it to receive tasks by provisioning a task queue. This sets up a Pub/Sub topic and an associated subscription to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic projects/turbine-demo/topics/example-engine\n",
      "Created subscription projects/turbine-demo/subscriptions/example-engine\n"
     ]
    }
   ],
   "source": [
    "example_engine.prepare_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding tasks\n",
    "In order to demonstrate that tasks can interact with Google Cloud storage, we create a simple blob file in a new bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.storage\n",
    "import random\n",
    "import string\n",
    "\n",
    "storage_client = google.cloud.storage.Client(project=config.project_id, credentials=config.credentials)\n",
    "bucket = storage_client.create_bucket(\"turbine-demo-\" + ''.join(random.choice(string.ascii_lowercase) for _ in range(10)))\n",
    "bucket.blob(\"cloud_input_file.txt\").upload_from_string(\"Some input data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assign some tasks to the engine. Each task consists of:\n",
    "1. A script to execute as the task.\n",
    "2. A list of files to download from GCS to the script working directory before executing the task.\n",
    "3. A list of files to upload to GCS from the script working directory after executing the task.\n",
    "\n",
    "For example, we add here a task that:\n",
    "1. Downloads the input file we created above from GCS to `abc/xyz/input.txt`.\n",
    "2. Sleeps for 10 seconds to simulate work.\n",
    "3. Prints a message to STDOUT.\n",
    "4. Prints the working directory contents to STDERR.\n",
    "5. Computes the word-count of the input file.\n",
    "6. Uploads both the input file and the word count to a worker-specific folder in GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    example_engine.add_task(\n",
    "        \"\\n\".join([\n",
    "            \"#!/bin/bash\",\n",
    "            \"sleep 10\",\n",
    "            \"echo \\\"Processing task %d\\\"\" % (i + 1),\n",
    "            \"ls 1>&2\",\n",
    "            \"wc abc/xyz/input.txt > abc/xyz/output.txt\",\n",
    "        ]),\n",
    "        inputs=[(\"abc/xyz/input.txt\", \"gs://{bucket}/cloud_input_file.txt\".format(bucket=bucket.name))],\n",
    "        outputs=[(\"abc/xyz\", \"gs://{bucket}/worker_{num}\".format(bucket=bucket.name, num=(i+1)))],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing tasks\n",
    "Given these tasks, we now want to instantiate VMs on the Google Cloud to execute the tasks. We first specify the type of VMs we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_engine.prepare_workers(machine_type=\"n1-standard-1\", preemptible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want to use `n1-standard-1` VMs that can be preempted. It is also possible to requisition GPUs at this stage. Note that we have not yet started any VMs and so are not yet being charged for their computation. This command merely creates an instance template. If desired, you can manually provision VMs using this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start VMs and complete tasks! With the following command, we start 2 VMs to process tasks. Although we have specified preemptible VMs, each VM will automatically try to remake itself if preempted. Each VM will also automatically deprovision itself when the queue is empty, to save money. (If you would like the VMs to keep running when there are no tasks remaining and, say, process new tasks as they are added, add `delete_when_done=False` as an argument to `prepare_workers`.)\n",
    "\n",
    "In the future, once I debug the REST API call, the gcloud argument will not be required and the code below will actually start the VMs. For the moment, please copy the gcloud-command produced by the code below into the terminal. This has the accidental benefit of confirming that you actually want to spend money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcloud compute instance-groups managed create example-engine --base-instance-name example-engine --size 2 --template projects/turbine-demo/global/instanceTemplates/example-engine --zone us-central1-a --project turbine-demo'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_engine.start_workers(2, gcloud=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the 2 VMs will start up, begin to process tasks, and deprovision itself once there are no tasks remaining. We can confirm this by waiting 2 minutes and ensuring no VMs remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of VMs initially in instance group: 2\n",
      "Number of VMs remaining in instance group: 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Number of VMs initially in instance group: \" + str(example_engine.workers()[0].info[\"targetSize\"]))\n",
    "time.sleep(120)\n",
    "print(\"Number of VMs remaining in instance group: \" + str(example_engine.workers()[0].info[\"targetSize\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By searching for `text:example-engine` in the [Stackdriver Logging](https://console.cloud.google.com/logs/viewer) Global log, we can see the logs from each VM. These include the tasks processed, the STDOUT and STDERR produced by each task, and any errors seen while interacting with GCS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log output from this example can be viewed [here](example_logs.txt). In this case, we see that each of the two workers initialized, processed two messages, and deprovisioned themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further confirm that the tasks were executed properly by consulting our Google Cloud Storage Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cloud_input_file.txt', 'worker_1/input.txt', 'worker_1/output.txt', 'worker_2/input.txt', 'worker_2/output.txt', 'worker_3/input.txt', 'worker_3/output.txt', 'worker_4/input.txt', 'worker_4/output.txt']\n",
      "b' 0  3 15 abc/xyz/input.txt\\n'\n"
     ]
    }
   ],
   "source": [
    "print([blob.name for blob in bucket.list_blobs()])\n",
    "print(bucket.blob(\"worker_2/output.txt\").download_as_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command cleans up the empty managed instance group left behind by the completed workers. If desired, the same `GCEEngine` object can continue to be used to add new tasks and run new workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting instance group manager example-engine\n"
     ]
    }
   ],
   "source": [
    "example_engine.cleanup_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following command deletes all resources provisioned by the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted subscription projects/turbine-demo/subscriptions/example-engine\n",
      "Deleted topic projects/turbine-demo/topics/example-engine\n",
      "Deleted instance template projects/turbine-demo/global/instanceTemplates/example-engine\n"
     ]
    }
   ],
   "source": [
    "example_engine.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
